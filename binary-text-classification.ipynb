{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfc2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "from ml_datasets import imdb\n",
    "import requests\n",
    "import csv\n",
    "train_data, valid_data = imdb()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e28ab93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_wikipedia():\n",
    "    url = \"https://olivers-things.s3.amazonaws.com/sample-wikipedia.json\"\n",
    "    articles = requests.get(url).json()\n",
    "    print(f\"fetched {len(articles)} articles\")\n",
    "    return articles\n",
    "\n",
    "def get_sample_wikipedia_untrained():\n",
    "    exclude = [a[2] for a in get_train_data()]\n",
    "    return [a for a in get_sample_wikipedia() if a[\"title\"] not in exclude]\n",
    "\n",
    "def get_train_data():\n",
    "    url = \"https://docs.google.com/spreadsheets/u/1/d/1ysgN8UoVY942gPVToxIEML_I-q27d9zTO6hAxoW5Yx4/export?format=csv&gid=0\"\n",
    "    tags = requests.get(url)\n",
    "    decoded = tags.content.decode('utf-8')\n",
    "    results = []\n",
    "    \n",
    "    for row in list(csv.reader(decoded.splitlines(), delimiter=','))[1:]:\n",
    "        try:\n",
    "            match = [a for a in articles if row[0] == a[\"title\"]][0]\n",
    "            title = match[\"title\"]\n",
    "            content = \" \".join(match[\"sentences\"])\n",
    "\n",
    "            if row[1] == \"0\":\n",
    "                results.append((content,\"neg\",title))\n",
    "            elif row[1] == \"1\":\n",
    "                results.append((content,\"pos\",title))\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {row[0]}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "def make_docs(data):\n",
    "    \"\"\"\n",
    "    this will take a list of texts and labels\n",
    "    and transform them in spacy documents\n",
    "    data: list(tuple(text, label))\n",
    "    returns: List(spacy.Doc.doc)\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    print(f\"training on {len(data)} docs\")\n",
    "    \n",
    "    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        if label == 'neg':\n",
    "            doc.cats[\"positive\"] = 0\n",
    "            doc.cats[\"negative\"] = 1\n",
    "        else:\n",
    "            doc.cats[\"positive\"] = 1\n",
    "            doc.cats[\"negative\"] = 0\n",
    "\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6bdf31",
   "metadata": {},
   "source": [
    "***\n",
    "***CREATE MODEL***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5315ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched 665 articles\n",
      "Error with Albert III\n",
      "Error with Madison County\n",
      "Error with Oswego County\n",
      "Error with Fort Collins\n",
      "Error with Lincoln\n",
      "Error with Soay\n",
      "Error with University of California\n",
      "Error with Celebration\n",
      "Error with Rockville\n",
      "Error with John Stuart\n",
      "Error with Harlingen\n"
     ]
    }
   ],
   "source": [
    "articles = get_sample_wikipedia()\n",
    "\n",
    "train_data = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeffb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_texts = 100\n",
    "# first we need to transform all the training data\n",
    "train_docs = make_docs(train_data[:num_texts])\n",
    "print(f\"training on {len(train_docs)} documents\")\n",
    "# then we save it in a binary file to disc\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"./data/train.spacy\")\n",
    "# repeat for validation data\n",
    "valid_docs = make_docs(valid_data[:num_texts])\n",
    "doc_bin = DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"./data/valid.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ce827",
   "metadata": {},
   "source": [
    "***\n",
    "***TEST MODEL***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45aac2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81d9aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with Albert III\n",
      "Error with Madison County\n",
      "Error with Oswego County\n",
      "Error with Fort Collins\n",
      "Error with Lincoln\n",
      "Error with Soay\n",
      "Error with University of California\n",
      "Error with Celebration\n",
      "Error with Rockville\n",
      "Error with John Stuart\n",
      "Error with Harlingen\n",
      "fetched 665 articles\n"
     ]
    }
   ],
   "source": [
    "untrained = get_sample_wikipedia_untrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89295716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Albert_III,_Duke_of_Saxony 0\n",
      "https://en.wikipedia.org/wiki/Book_of_Hosea 1\n",
      "https://en.wikipedia.org/wiki/Biotite 1\n",
      "https://en.wikipedia.org/wiki/Casino 0\n",
      "https://en.wikipedia.org/wiki/Celtic_music 0\n",
      "https://en.wikipedia.org/wiki/Common_descent 1\n",
      "https://en.wikipedia.org/wiki/Bubble_Bobble 0\n",
      "https://en.wikipedia.org/wiki/Constantinople 0\n",
      "https://en.wikipedia.org/wiki/California 0\n",
      "https://en.wikipedia.org/wiki/Community_college 1\n",
      "https://en.wikipedia.org/wiki/Casino_game 1\n",
      "https://en.wikipedia.org/wiki/Curium 1\n",
      "https://en.wikipedia.org/wiki/Politics_of_the_Czech_Republic 0\n",
      "https://en.wikipedia.org/wiki/Chicano 0\n",
      "https://en.wikipedia.org/wiki/Carabiner 1\n",
      "https://en.wikipedia.org/wiki/Cardiff 0\n",
      "https://en.wikipedia.org/wiki/Carlo_Goldoni 0\n",
      "https://en.wikipedia.org/wiki/Ceuta 0\n",
      "https://en.wikipedia.org/wiki/Chicago_Bears 0\n",
      "https://en.wikipedia.org/wiki/Constantin_von_Tischendorf 0\n",
      "https://en.wikipedia.org/wiki/Cetus 0\n",
      "https://en.wikipedia.org/wiki/Carnivore 1\n",
      "https://en.wikipedia.org/wiki/Cygwin 1\n",
      "https://en.wikipedia.org/wiki/Chakra 1\n",
      "https://en.wikipedia.org/wiki/Ceres_Brewery 0\n",
      "https://en.wikipedia.org/wiki/Central_Powers 0\n",
      "https://en.wikipedia.org/wiki/Antisemitism_in_Christianity 1\n",
      "https://en.wikipedia.org/wiki/Cricket_World_Cup 0\n",
      "https://en.wikipedia.org/wiki/Classification_of_finite_simple_groups 1\n",
      "https://en.wikipedia.org/wiki/Calendar_date 0\n",
      "https://en.wikipedia.org/wiki/Christianity_and_Judaism 1\n",
      "https://en.wikipedia.org/wiki/Coordination_complex 1\n",
      "https://en.wikipedia.org/wiki/Chinese_remainder_theorem 1\n",
      "https://en.wikipedia.org/wiki/Clive_Barker 0\n",
      "https://en.wikipedia.org/wiki/Logical_disjunction 1\n",
      "https://en.wikipedia.org/wiki/Captain_America 0\n",
      "https://en.wikipedia.org/wiki/Calculator 0\n",
      "https://en.wikipedia.org/wiki/Definition_of_music 1\n",
      "https://en.wikipedia.org/wiki/History_of_the_Dominican_Republic 0\n",
      "https://en.wikipedia.org/wiki/Duesberg_hypothesis 1\n",
      "https://en.wikipedia.org/wiki/HM_Prison_Dartmoor 0\n",
      "https://en.wikipedia.org/wiki/Economy_of_Denmark 0\n",
      "https://en.wikipedia.org/wiki/Deuterium 1\n",
      "https://en.wikipedia.org/wiki/Declination 1\n",
      "https://en.wikipedia.org/wiki/Slalom_skiing 0\n",
      "https://en.wikipedia.org/wiki/Dmitri_Shostakovich 0\n",
      "https://en.wikipedia.org/wiki/Didgeridoo 1\n",
      "https://en.wikipedia.org/wiki/Existence 1\n",
      "https://en.wikipedia.org/wiki/December_19 0\n",
      "https://en.wikipedia.org/wiki/Doctor_V64 1\n"
     ]
    }
   ],
   "source": [
    "def wikipedia_link(title):\n",
    "    return f\"https://en.wikipedia.org/wiki/{title.replace(' ', '_')}\"\n",
    "\n",
    "for a in untrained[0:50]:\n",
    "    doc = nlp(\" \".join(a[\"sentences\"]))\n",
    "    result = 1 if doc.cats['positive'] > 0.5 else 0\n",
    "    print(wikipedia_link(a[\"title\"]), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b9ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c4c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
